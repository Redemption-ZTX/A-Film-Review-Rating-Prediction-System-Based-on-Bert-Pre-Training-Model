# 导入必要的库
import gradio as gr
from transformers import BertTokenizer, BertForSequenceClassification
import torch

# 从保存的检查点加载预先训练好的BERT模型
model = BertForSequenceClassification.from_pretrained('results/checkpoint-2130')
# 加载BERT分词器，用于中文文本
tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')

# 定义预测函数
def predict(text):
    # 使用分词器处理输入文本，转换为模型可接受的格式
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=256)
    # 不计算梯度，只做前向传播，以提高预测速度
    with torch.no_grad():
        logits = model(**inputs).logits  # 获取模型的原始输出（未经softmax处理）
    # 对logits使用softmax函数，得到每个类别的预测概率
    predictions = torch.softmax(logits, dim=-1)
    # 将预测概率转换为一个字典，键为评分（1星到5星），值为对应的概率
    return {f'{i + 1} stars': float(predictions[0][i]) for i in range(5)}

# 使用Gradio创建界面，将predict函数作为后端，输入为文本，输出为标签
iface = gr.Interface(fn=predict, inputs="text", outputs="label")

# 启动界面，该界面将在默认浏览器中打开
iface.launch()
